{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an RNN from Scratch\n",
    "\n",
    "## Introduction: Why Are We Doing This?\n",
    "Sure, we could just `import transformers` and call it a day. But where's the fun in that? Besides, understanding RNNs is like understanding your grandparents' stories - they may seem outdated, but there's wisdom in there somewhere.\n",
    "\n",
    "## What We're Building\n",
    "We're implementing a vanilla RNN completely from scratch, armed with nothing but:\n",
    "- NumPy \n",
    "- Basic calculus \n",
    "- Unwavering optimism (crucial for debugging backprop)\n",
    "\n",
    "Our mission? Teaching a neural network to figure out parts of speech.\n",
    "\n",
    "## The Game Plan\n",
    "1. Build an RNN cell (the LEGO brick of sequence processing)\n",
    "2. Stack them together (the LEGO Death Star of NLP)\n",
    "3. Make it learn through backpropagation (the \"please work\" phase)\n",
    "4. Apply it to POS tagging (because someone has to know what adjectives are)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Structure\n",
    "The recurrent neural network (RNN) processes a sequence of inputs $x = (x^{<1>}, x^{<2>}, ..., x^{<T_x>})$ using a single RNN cell. \n",
    "The RNN cell takes as input the current input $x^{<t>}$ and the previous hidden state $a^{<t-1>}$, \n",
    "and outputs the current hidden state $a^{<t>}$ and prediction $y^{<t>}$.\n",
    "\n",
    "The RNN cell is defined as:\n",
    "$$a^{<t>} = \\tanh(W_{aa} a^{<t-1>} + W_{ax} x^{<t>} + b_a)$$\n",
    "$$\\hat{y}^{<t>} = softmax(W_{ya}a^{<t>} + b_y)$$\n",
    "\n",
    "![local image](./Images/RNN.png)\n",
    "\n",
    "\n",
    "## The Mathematics Behind RNNs\n",
    "For each time step t, an RNN processes:\n",
    "- Input: $x^{<t>}$ (current word embedding)\n",
    "- Previous hidden state: $a^{<t-1>}$ (carrying context)\n",
    "- Target: $y^{<t>}$ (true POS tag)\n",
    "\n",
    "The forward pass comprises two key equations:\n",
    "1. Hidden state update:\n",
    "   $a^{<t>} = \\tanh(W_{ax}x^{<t>} + W_{aa}a^{<t-1>} + b_a)$\n",
    "   where:\n",
    "   - $W_{ax}$: input-to-hidden weights\n",
    "   - $W_{aa}$: hidden-to-hidden weights\n",
    "   - $b_a$: hidden bias\n",
    "\n",
    "2. Output prediction:\n",
    "   $\\hat{y}^{<t>} = \\text{softmax}(W_{ya}a^{<t>} + b_y)$\n",
    "   where:\n",
    "   - $W_{ya}$: hidden-to-output weights\n",
    "   - $b_y$: output bias\n",
    "\n",
    "\n",
    "The implementation of a signle RNN cell is as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_cell_forward(xt, yt, a_prev, parameters):\n",
    "    \"\"\"\n",
    "    Implements a single forward step of the RNN-cell.\n",
    "\n",
    "    Arguments:\n",
    "    xt -- input data at timestep \"t\", numpy array of shape (n_x, b) \n",
    "    yt -- true values at timestep \"t\", numpy array of shape (n_y, b)\n",
    "    a_prev -- Hidden state at timestep \"t-1\", numpy array of shape (n_a, b)\n",
    "    parameters -- python dictionary containing:\n",
    "                 Wax -- Input-to-hidden weights (n_a, n_x)\n",
    "                 Waa -- Hidden-to-hidden weights (n_a, n_a)\n",
    "                 Wya -- Hidden-to-output weights (n_y, n_a)\n",
    "                 ba -- Hidden bias (n_a, 1)\n",
    "                 by -- Output bias (n_y, 1)\n",
    "\n",
    "    Returns:\n",
    "    a_next -- next hidden state, shape (n_a, b)\n",
    "    yt_pred -- prediction at timestep \"t\", shape (n_y, b)\n",
    "    cache -- tuple for backward pass (a_next, a_prev, xt, yt, parameters, yt_pred)\n",
    "    \"\"\"\n",
    "    # Unpack parameters\n",
    "    Wax = parameters['Wax']\n",
    "    Waa = parameters['Waa']\n",
    "    Wya = parameters['Wya']\n",
    "    ba = parameters['ba']\n",
    "    by = parameters['by']\n",
    "\n",
    "    # Compute next hidden state using tanh activation\n",
    "    a_next = np.tanh(np.dot(Wax, xt) + np.dot(Waa, a_prev) + ba)\n",
    "\n",
    "    # Compute prediction using softmax activation\n",
    "    yt_pred = softmax(np.dot(Wya, a_next) + by)\n",
    "\n",
    "    # Store values needed for backward pass\n",
    "    cache = (a_next, a_prev, xt, yt, parameters, yt_pred)\n",
    "\n",
    "    return a_next, yt_pred, cache\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward pass through time\n",
    "\n",
    "## Full Sequence Forward Propagation\n",
    "After implementing a single RNN cell, we need to process entire sequences. For POS tagging, this means handling complete sentences where each word (token) is processed sequentially while maintaining contextual information through hidden states.\n",
    "\n",
    "### Mathematical Formulation\n",
    "For a sequence of length T, we iteratively apply:\n",
    "1. Hidden state propagation:\n",
    "   $a^{<t>} = \\tanh(W_{ax}x^{<t>} + W_{aa}a^{<t-1>} + b_a)$\n",
    "   for t = 1, ..., T\n",
    "\n",
    "2. Predictions at each step:\n",
    "   $\\hat{y}^{<t>} = \\text{softmax}(W_{ya}a^{<t>} + b_y)$\n",
    "\n",
    "### Dimensions and Notation\n",
    "- **Batch processing**: b sequences processed simultaneously\n",
    "- **Input dimensions**: (n_x, b, T_x) where:\n",
    "  - n_x: embedding dimension\n",
    "  - b: batch size\n",
    "  - T_x: sequence length\n",
    "- **Hidden state**: (n_a, b) per time step\n",
    "- **Output**: (n_y, b) predictions per time step\n",
    "\n",
    "### Implementation\n",
    "The following function implements forward propagation through time, maintaining caches for backpropagation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_forward(x, y, a0, parameters):\n",
    "    \"\"\"\n",
    "    Implement forward propagation for a RNN over an entire sequence.\n",
    "\n",
    "    Arguments:\n",
    "    x -- Input data, numpy array of shape (n_x, b, T_x)\n",
    "    y -- True values, numpy array of shape (n_y, b, T_x)\n",
    "    a0 -- Initial hidden state, numpy array of shape (n_a, b)\n",
    "    parameters -- python dictionary containing:\n",
    "                 Wax -- Input-to-hidden weights (n_a, n_x)\n",
    "                 Waa -- Hidden-to-hidden weights (n_a, n_a)\n",
    "                 Wya -- Hidden-to-output weights (n_y, n_a)\n",
    "                 ba -- Hidden bias (n_a, 1)\n",
    "                 by -- Output bias (n_y, 1)\n",
    "\n",
    "    Returns:\n",
    "    a -- Hidden states for all timesteps, shape (n_a, b, T_x)\n",
    "    y_pred -- Predictions for all timesteps, shape (n_y, b, T_x)\n",
    "    caches -- List of caches containing for each timestep:\n",
    "              (a_next, a_prev, xt, yt, parameters, yt_pred)\n",
    "    \"\"\"\n",
    "    # Get dimensions from input shapes\n",
    "    n_x, b, T_x = x.shape\n",
    "    n_y, n_a = parameters[\"Wya\"].shape\n",
    "    \n",
    "    # Initialize outputs and hidden states\n",
    "    a = np.zeros((n_a, b, T_x))\n",
    "    y_pred = np.zeros((n_y, b, T_x))\n",
    "    a_next = a0\n",
    "    \n",
    "    # Store caches for backward pass\n",
    "    caches = []\n",
    "    \n",
    "    # Forward propagation over time steps\n",
    "    for t in range(T_x):\n",
    "        # Get current timestep input and true value\n",
    "        xt = x[:,:,t]\n",
    "        yt = y[:,:,t]\n",
    "        \n",
    "        # Forward step for current timestep\n",
    "        a_next, yt_pred, cache = rnn_cell_forward(xt, yt, a_next, parameters)\n",
    "        \n",
    "        # Store current hidden state and prediction\n",
    "        a[:,:,t] = a_next\n",
    "        y_pred[:,:,t] = yt_pred\n",
    "        \n",
    "        # Store cache for backward pass\n",
    "        caches.append(cache)\n",
    "    \n",
    "    return a, y_pred, caches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation Through a Single RNN Cell\n",
    "The backward pass computes gradients for a single timestep, which will be used to update the network parameters. This involves applying the chain rule through both the output and hidden state computations.\n",
    "\n",
    "### Gradient Flow\n",
    "For a single RNN cell, we need to compute gradients through:\n",
    "1. Output layer (cross-entropy loss):\n",
    "   - $\\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}^{<t>}} = \\hat{y}^{<t>} - y^{<t>}$ (for cross-entropy)\n",
    "   - $\\frac{\\partial \\mathcal{L}}{\\partial W_{ya}} = \\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}^{<t>}} (a^{<t>})^T$\n",
    "\n",
    "2. Hidden state:\n",
    "   - $\\frac{\\partial \\mathcal{L}}{\\partial a^{<t>}} = W_{ya}^T\\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}^{<t>}} + \\frac{\\partial \\mathcal{L}}{\\partial a^{<t+1>}}$\n",
    "   - $\\frac{\\partial \\mathcal{L}}{\\partial z^{<t>}} = \\frac{\\partial \\mathcal{L}}{\\partial a^{<t>}} \\odot (1-(a^{<t>})^2)$ (tanh derivative)\n",
    "\n",
    "3. Input and previous state:\n",
    "   - $\\frac{\\partial \\mathcal{L}}{\\partial W_{ax}} = \\frac{\\partial \\mathcal{L}}{\\partial z^{<t>}}(x^{<t>})^T$\n",
    "   - $\\frac{\\partial \\mathcal{L}}{\\partial W_{aa}} = \\frac{\\partial \\mathcal{L}}{\\partial z^{<t>}}(a^{<t-1>})^T$\n",
    "\n",
    "\n",
    "\n",
    "![local image](./Images/Back_Propagation.png)\n",
    "\n",
    "\n",
    "\n",
    "### Implementation\n",
    "The following function computes all necessary gradients for a single timestep:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_cell_backward(da_next, cache):\n",
    "    \"\"\"\n",
    "    Implements the backward pass for a single RNN cell timestep.\n",
    "\n",
    "    Arguments:\n",
    "    da_next -- Gradient of loss with respect to next hidden state, shape (n_a, b)\n",
    "    cache -- tuple containing:\n",
    "        a_next -- Next hidden state\n",
    "        a_prev -- Previous hidden state\n",
    "        xt -- Input at current timestep\n",
    "        y_target -- True values\n",
    "        parameters -- Dictionary of weights and biases\n",
    "        y_pred -- Predictions at current timestep\n",
    "\n",
    "    Returns:\n",
    "    gradients -- Dictionary containing:\n",
    "        dx -- Gradients w.r.t input data (n_x, b)\n",
    "        da_prev -- Gradients w.r.t previous hidden state (n_a, b)\n",
    "        dWax -- Gradients w.r.t input-to-hidden weights (n_a, n_x)\n",
    "        dWaa -- Gradients w.r.t hidden-to-hidden weights (n_a, n_a)\n",
    "        dWya -- Gradients w.r.t hidden-to-output weights (n_y, n_a)\n",
    "        dba -- Gradients w.r.t hidden bias (n_a, 1)\n",
    "        dby -- Gradients w.r.t output bias (n_y, 1)\n",
    "    \"\"\"\n",
    "    # Retrieve values from cache\n",
    "    a_next, a_prev, xt, y_target, parameters, y_pred = cache\n",
    "    \n",
    "    # Retrieve parameters\n",
    "    Wax = parameters[\"Wax\"]\n",
    "    Waa = parameters[\"Waa\"]\n",
    "    Wya = parameters[\"Wya\"]\n",
    "    \n",
    "    # Output layer gradients\n",
    "    dy = y_pred - y_target                  # Cross-entropy loss derivative\n",
    "    dWya = np.dot(dy, a_next.T)            # Hidden-to-output weights gradient\n",
    "    dby = np.sum(dy, axis=1, keepdims=True) # Output bias gradient\n",
    "    \n",
    "    # Hidden layer gradients\n",
    "    da = np.dot(Wya.T, dy) + da_next       # Add gradient from next cell\n",
    "    dtanh = (1 - a_next**2) * da           # Tanh derivative\n",
    "    \n",
    "    # Weight and bias gradients\n",
    "    dWax = np.dot(dtanh, xt.T)             # Input-to-hidden weights gradient\n",
    "    dWaa = np.dot(dtanh, a_prev.T)         # Hidden-to-hidden weights gradient\n",
    "    dba = np.sum(dtanh, axis=1, keepdims=True)  # Hidden bias gradient\n",
    "    \n",
    "    # Input gradients\n",
    "    dx = np.dot(Wax.T, dtanh)              # Input gradient\n",
    "    da_prev = np.dot(Waa.T, dtanh)         # Previous hidden state gradient\n",
    "    \n",
    "    # Store gradients\n",
    "    gradients = {\n",
    "        'dx': dx,\n",
    "        'da_prev': da_prev, \n",
    "        'dWax': dWax,\n",
    "        'dWaa': dWaa,\n",
    "        'dWya': dWya,\n",
    "        'dba': dba,\n",
    "        'dby': dby\n",
    "    }\n",
    "    \n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation Through Time (BPTT)\n",
    "Backpropagation through time extends the backward pass to entire sequences, with a crucial characteristic: weight sharing across time steps. The same weights ($W_{ax}$, $W_{aa}$, $W_{ya}$) are used at each time step, which leads to an important implementation detail: gradients must be accumulated across all time steps.\n",
    "\n",
    "### Weight Sharing and Gradient Accumulation\n",
    "For each weight matrix, the total gradient is the sum of gradients from all time steps:\n",
    "\n",
    "$\\frac{\\partial \\mathcal{L}}{\\partial W_{ax}} = \\sum_{t=1}^T \\frac{\\partial \\mathcal{L}_t}{\\partial W_{ax}}$\n",
    "\n",
    "$\\frac{\\partial \\mathcal{L}}{\\partial W_{aa}} = \\sum_{t=1}^T \\frac{\\partial \\mathcal{L}_t}{\\partial W_{aa}}$\n",
    "\n",
    "$\\frac{\\partial \\mathcal{L}}{\\partial W_{ya}} = \\sum_{t=1}^T \\frac{\\partial \\mathcal{L}_t}{\\partial W_{ya}}$\n",
    "\n",
    "### Gradient Flow Through Time\n",
    "The backward pass processes the sequence in reverse order because:\n",
    "1. Later time steps affect earlier ones through hidden states\n",
    "2. Gradient at time t depends on future time steps t+1, t+2, ..., T\n",
    "3. Initial hidden state (a0) gradient accumulates from all time steps\n",
    "\n",
    "### Implementation\n",
    "The following function implements BPTT, accumulating gradients across the sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_backward(caches):\n",
    "    \"\"\"\n",
    "    Implement backward pass for a RNN over an entire sequence of input data.\n",
    "\n",
    "    Arguments:\n",
    "    caches -- list containing tuples for each timestep t:\n",
    "              (a_next, a_prev, xt, yt, parameters, y_pred)\n",
    "\n",
    "    Returns:\n",
    "    gradients -- Dictionary containing:\n",
    "                dx_total -- Gradient w.r.t. input data (n_x, b, T_x)\n",
    "                da0 -- Gradient w.r.t. initial hidden state (n_a, b)\n",
    "                dWax_total -- Gradient w.r.t. input weights (n_a, n_x)\n",
    "                dWaa_total -- Gradient w.r.t. hidden weights (n_a, n_a)\n",
    "                dWya_total -- Gradient w.r.t. output weights (n_y, n_a)\n",
    "                dba_total -- Gradient w.r.t. hidden bias (n_a, 1)\n",
    "                dby_total -- Gradient w.r.t. output bias (n_y, 1)\n",
    "    \"\"\"\n",
    "    # Retrieve dimensions from first cache\n",
    "    (a1, a0, x1, y1, parameters, _) = caches[0]\n",
    "    n_a, b = a0.shape\n",
    "    n_x, _ = x1.shape\n",
    "    n_y, _ = y1.shape\n",
    "    T_x = len(caches)\n",
    "    \n",
    "    # Initialize gradients\n",
    "    dx = np.zeros((n_x, b, T_x))\n",
    "    dWax = np.zeros((n_a, n_x))\n",
    "    dWaa = np.zeros((n_a, n_a))\n",
    "    dWya = np.zeros((n_y, n_a))\n",
    "    dba = np.zeros((n_a, 1))\n",
    "    dby = np.zeros((n_y, 1))\n",
    "    da0 = np.zeros((n_a, b))\n",
    "    \n",
    "    # Initialize gradient for next hidden state\n",
    "    da_next = np.zeros((n_a, b))\n",
    "    \n",
    "    # Backpropagate through time\n",
    "    for t in reversed(range(T_x)):\n",
    "        # Compute gradients at current timestep\n",
    "        gradients = rnn_cell_backward(da_next, caches[t])\n",
    "        \n",
    "        # Extract gradients for current timestep\n",
    "        dx_t = gradients['dx']\n",
    "        da_next = gradients['da_prev']\n",
    "        \n",
    "        # Store dx for current timestep\n",
    "        dx[:,:,t] = dx_t\n",
    "        \n",
    "        # Accumulate weight gradients\n",
    "        dWax += gradients['dWax']\n",
    "        dWaa += gradients['dWaa']\n",
    "        dWya += gradients['dWya']\n",
    "        dba += gradients['dba']\n",
    "        dby += gradients['dby']\n",
    "    \n",
    "    # da0 is the gradient w.r.t. the initial hidden state\n",
    "    da0 = da_next\n",
    "    \n",
    "    # Store all gradients in dictionary\n",
    "    gradients = {\n",
    "        'dx_total': dx,\n",
    "        'da0': da0,\n",
    "        'dWax_total': dWax,\n",
    "        'dWaa_total': dWaa,\n",
    "        'dWya_total': dWya,\n",
    "        'dba_total': dba,\n",
    "        'dby_total': dby\n",
    "    }\n",
    "    \n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reality Check! 🤔\n",
    "\n",
    "Let's make sure our mathematical masterpiece is functioning.\n",
    "\n",
    "### What We're Testing:\n",
    "- Forward pass\n",
    "- Backward pass (aka \"The Ghost of Gradients Past\")\n",
    "- Shapes\n",
    "- Probabilities (making sure they sum to 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "Input (x): (10, 4, 20)\n",
      "Targets (y): (5, 4, 20)\n",
      "Initial hidden state (a0): (16, 4)\n",
      "\n",
      "Forward pass:\n",
      "--------------------------------------------------\n",
      "Single cell (t=0):\n",
      "Input timestep (xt): (10, 4)\n",
      "Hidden state (a_next): (16, 4)\n",
      "Prediction (yt_pred): (5, 4)\n",
      "Prediction sum (should be 1): [0.24991465 0.25018465 0.24993291]\n",
      "\n",
      "Full sequence:\n",
      "All hidden states (a): (16, 4, 20)\n",
      "All predictions (y_pred): (5, 4, 20)\n",
      "Number of cached timesteps: 20\n",
      "\n",
      "Backward pass:\n",
      "--------------------------------------------------\n",
      "Single cell backward (last timestep):\n",
      "dx: (10, 4)\n",
      "da_prev: (16, 4)\n",
      "dWax: (16, 10)\n",
      "dWaa: (16, 16)\n",
      "dWya: (5, 16)\n",
      "dba: (16, 1)\n",
      "dby: (5, 1)\n",
      "\n",
      "Full sequence backward:\n",
      "dx_total: (10, 4, 20)\n",
      "da0: (16, 4)\n",
      "dWax_total: (16, 10)\n",
      "dWaa_total: (16, 16)\n",
      "dWya_total: (5, 16)\n",
      "dba_total: (16, 1)\n",
      "dby_total: (5, 1)\n",
      "\n",
      "Sample values:\n",
      "--------------------------------------------------\n",
      "First prediction probabilities (timestep 0, first sample):\n",
      "[0.05001189 0.04996267 0.04996702 0.04999154 0.04998153]\n",
      "\n",
      "First target (timestep 0, first sample):\n",
      "[0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define dimensions\n",
    "n_x = 10      # embedding size\n",
    "n_a = 16      # hidden state size\n",
    "n_y = 5       # vocabulary size\n",
    "b = 4         # batch size\n",
    "T_x = 20      # sequence length\n",
    "\n",
    "# Create dummy data\n",
    "x = np.random.randn(n_x, b, T_x)  # Input sequences\n",
    "y = np.random.randint(0, n_y, size=(n_y, b, T_x))  # One-hot encoded targets\n",
    "y = (y == np.arange(n_y)[:, None, None]).astype(int)  # Convert to one-hot\n",
    "\n",
    "# Initialize parameters\n",
    "parameters = {\n",
    "    'Wax': np.random.randn(n_a, n_x) * 0.01,   # Input weights\n",
    "    'Waa': np.random.randn(n_a, n_a) * 0.01,   # Hidden weights\n",
    "    'Wya': np.random.randn(n_y, n_a) * 0.01,   # Output weights\n",
    "    'ba': np.zeros((n_a, 1)),                   # Hidden bias\n",
    "    'by': np.zeros((n_y, 1))                    # Output bias\n",
    "}\n",
    "\n",
    "# Initialize hidden state\n",
    "a0 = np.zeros((n_a, b))\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(f\"Input (x): {x.shape}\")\n",
    "print(f\"Targets (y): {y.shape}\")\n",
    "print(f\"Initial hidden state (a0): {a0.shape}\\n\")\n",
    "\n",
    "# Forward pass\n",
    "print(\"Forward pass:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# First, show single cell forward\n",
    "print(\"Single cell (t=0):\")\n",
    "xt = x[:,:,0]\n",
    "yt = y[:,:,0]\n",
    "a_next, yt_pred, cache = rnn_cell_forward(xt, yt, a0, parameters)\n",
    "print(f\"Input timestep (xt): {xt.shape}\")\n",
    "print(f\"Hidden state (a_next): {a_next.shape}\")\n",
    "print(f\"Prediction (yt_pred): {yt_pred.shape}\")\n",
    "print(f\"Prediction sum (should be 1): {yt_pred.sum(axis=0)[:3]}\\n\")  # Show first 3 samples\n",
    "\n",
    "# Then, full sequence forward\n",
    "print(\"Full sequence:\")\n",
    "a, y_pred, caches = rnn_forward(x, y, a0, parameters)\n",
    "print(f\"All hidden states (a): {a.shape}\")\n",
    "print(f\"All predictions (y_pred): {y_pred.shape}\")\n",
    "print(f\"Number of cached timesteps: {len(caches)}\\n\")\n",
    "\n",
    "# Backward pass\n",
    "print(\"Backward pass:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# First, show single cell backward for last timestep\n",
    "print(\"Single cell backward (last timestep):\")\n",
    "da_next = np.random.randn(n_a, b) * 0.01\n",
    "gradients = rnn_cell_backward(da_next, caches[-1])\n",
    "for key, value in gradients.items():\n",
    "    print(f\"{key}: {value.shape}\")\n",
    "print()\n",
    "\n",
    "# Then, full sequence backward\n",
    "print(\"Full sequence backward:\")\n",
    "gradients = rnn_backward(caches)\n",
    "for key, value in gradients.items():\n",
    "    print(f\"{key}: {value.shape}\")\n",
    "\n",
    "# Show some actual values\n",
    "print(\"\\nSample values:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"First prediction probabilities (timestep 0, first sample):\\n{y_pred[:,0,0]}\")\n",
    "print(f\"\\nFirst target (timestep 0, first sample):\\n{y[:,0,0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application: Part-of-Speech Tagging\n",
    "\n",
    "Part-of-Speech (POS) tagging is a fundamental task in Natural Language Processing where we assign grammatical tags to words based on their context. This serves as an excellent application for our RNN implementation as it requires:\n",
    "1. Sequential processing of words\n",
    "2. Contextual understanding\n",
    "3. Multi-class classification\n",
    "\n",
    "### Data Sources\n",
    "We utilize three standard corpora from NLTK:\n",
    "- Penn Treebank: Wall Street Journal text with manual POS annotations\n",
    "- Brown Corpus: American English text across multiple genres\n",
    "- CoNLL-2000: Text annotated for chunking tasks\n",
    "\n",
    "These corpora use the Universal POS tagset, providing a standardized set of grammatical categories across different texts.\n",
    "\n",
    "### Data Preparation\n",
    "The implementation requires:\n",
    "1. Converting text to numerical representations\n",
    "2. Creating consistent sequence lengths\n",
    "3. Generating appropriate input-output pairs for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to /home/sorous/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package brown to /home/sorous/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package conll2000 to /home/sorous/nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /home/sorous/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Download required NLTK datasets if not already present\n",
    "nltk.download('treebank')    # Penn Treebank corpus\n",
    "nltk.download('brown')       # Brown corpus\n",
    "nltk.download('conll2000')   # CoNLL-2000 chunking corpus\n",
    "nltk.download('universal_tagset')  # Universal POS tag set\n",
    "\n",
    "from nltk.corpus import treebank, brown, conll2000\n",
    "\n",
    "# Load tagged sentences from different corpora using universal tagset\n",
    "treebank_corpus = treebank.tagged_sents(tagset = 'universal')\n",
    "brown_corpus = brown.tagged_sents(tagset = 'universal')\n",
    "conll_corpus = conll2000.tagged_sents(tagset = 'universal')\n",
    "\n",
    "# Combine all corpora into one dataset\n",
    "tagged_sentences = treebank_corpus + brown_corpus + conll_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization and Format\n",
    "\n",
    "To better understand our POS tagging task, let's examine a sample sentence from our dataset. The data is structured as pairs of words and their corresponding POS tags.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example tagged sentence structure:\n",
      "\n",
      "Sample data: [('Mr.', 'NOUN'), ('Vinken', 'NOUN'), ('is', 'VERB'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Elsevier', 'NOUN'), ('N.V.', 'NOUN'), (',', '.'), ('the', 'DET'), ('Dutch', 'NOUN'), ('publishing', 'VERB'), ('group', 'NOUN'), ('.', '.')]\n",
      "\n",
      "------------------------- Word-tag pairs -------------------------\n",
      "Mr.             -> NOUN\n",
      "Vinken          -> NOUN\n",
      "is              -> VERB\n",
      "chairman        -> NOUN\n",
      "of              -> ADP\n",
      "Elsevier        -> NOUN\n",
      "N.V.            -> NOUN\n",
      ",               -> .\n",
      "the             -> DET\n",
      "Dutch           -> NOUN\n",
      "publishing      -> VERB\n",
      "group           -> NOUN\n",
      ".               -> .\n",
      "------------------------- Or Better Shown -------------------------\n",
      "Sentence: Mr.        Vinken     is         chairman   of         Elsevier   N.V.       ,          the        Dutch      publishing group      .         \n",
      "Tags:     NOUN       NOUN       VERB       NOUN       ADP        NOUN       NOUN       .          DET        NOUN       VERB       NOUN       .         \n"
     ]
    }
   ],
   "source": [
    "# Display an example sentence with its POS tags\n",
    "example_sentence = tagged_sentences[1]\n",
    "print(\"Example tagged sentence structure:\\n\")\n",
    "\n",
    "print(f\"Sample data: {example_sentence}\\n\")\n",
    "print('-' * 25, 'Word-tag pairs', '-' * 25)\n",
    "for word, tag in example_sentence:\n",
    "    print(f\"{word:15} -> {tag}\")\n",
    "\n",
    "print('-' * 25, 'Or Better Shown', '-' * 25)\n",
    "\n",
    "# Separate words and tags\n",
    "words, tags = zip(*example_sentence)\n",
    "\n",
    "# Find maximum word length for padding\n",
    "max_len = max(len(word) for word in words)\n",
    "\n",
    "# Create aligned strings\n",
    "aligned_words = ' '.join(word.ljust(max_len) for word in words)\n",
    "aligned_tags  = ' '.join(tag.ljust(max_len) for tag in tags)\n",
    "\n",
    "print(f\"Sentence: {aligned_words}\")\n",
    "print(f\"Tags:     {aligned_tags}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing: Creating Word and Tag Sequences\n",
    "\n",
    "After examining the data format, we need to preprocess our tagged sentences into a format suitable for the RNN. This involves:\n",
    "\n",
    "1. Separating words and tags into distinct sequences\n",
    "2. Converting all words to lowercase for consistency\n",
    "3. Maintaining parallel sequences where:\n",
    "   - X[i] contains the word sequence for sentence i\n",
    "   - Y[i] contains the corresponding tag sequence\n",
    "\n",
    "This step transforms our data from paired word-tag tuples into separate sequences while preserving the alignment between words and their POS tags.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate words and tags into two lists of sequences and gather statistics\n",
    "X = []  # Will contain sequences of words\n",
    "Y = []  # Will contain sequences of POS tags\n",
    "\n",
    "for sentence in tagged_sentences:\n",
    "    # Split each (word, tag) tuple in the sentence into separate lists\n",
    "    words, tags = zip(*sentence)\n",
    "    \n",
    "    # Convert words to lowercase and update statistics\n",
    "    words = [word.lower() for word in words]\n",
    "    \n",
    "    # Add the sequences to our dataset\n",
    "    X.append(words)\n",
    "    Y.append(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Statistics \n",
    "\n",
    "Let's check a few things,\n",
    "   - Total number of training sentences\n",
    "   - Vocabulary size (unique words)\n",
    "   - Number of distinct POS tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Statistics:\n",
      "--------------------------------------------------\n",
      "Total number of sentences: 72,202\n",
      "Vocabulary size: 59,448 words\n",
      "Tag set size: 12 tags\n",
      "\n",
      "Universal POS Tags:\n",
      "- .\n",
      "- ADJ\n",
      "- ADP\n",
      "- ADV\n",
      "- CONJ\n",
      "- DET\n",
      "- NOUN\n",
      "- NUM\n",
      "- PRON\n",
      "- PRT\n",
      "- VERB\n",
      "- X\n"
     ]
    }
   ],
   "source": [
    "# Calculate unique words and tags\n",
    "unique_words = set(word for sentence in X for word in sentence)\n",
    "unique_tags = set(tag for sentence in Y for tag in sentence)\n",
    "\n",
    "# Display dataset statistics\n",
    "print(\"Dataset Statistics:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Total number of sentences: {len(X):,}\")\n",
    "print(f\"Vocabulary size: {len(unique_words):,} words\")\n",
    "print(f\"Tag set size: {len(unique_tags)} tags\")\n",
    "\n",
    "print(\"\\nUniversal POS Tags:\")\n",
    "for tag in sorted(unique_tags):\n",
    "    print(f\"- {tag}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings\n",
    "### Word Embeddings\n",
    "Rather than training word embeddings from scratch (which would require serious computational resources and a level of patience I haven't unlocked yet), we utilize Word2Vec to generate pre-trained embeddings. These embeddings are frozen during training, meaning:\n",
    "- We benefit from pre-learned word representations\n",
    "- Only RNN parameters are updated during training\n",
    "- Our GPUs thank us for this merciful decision\n",
    "\n",
    "The trade-off? We sacrifice the ability to fine-tune word representations, but sometimes you have to choose between perfection and getting things done before the heat death of the universe.\n",
    "\n",
    "Dimensions:\n",
    "- Embedding size: 100 dimensions\n",
    "- Maximum sequence length: 100 tokens\n",
    "- Each word mapped to its corresponding embedding vector\n",
    "\n",
    "### POS Tag Encoding\n",
    "Tags are encoded using one-hot vectors, where:\n",
    "- Each tag maps to a 13-dimensional binary vector\n",
    "- First position reserved for padding\n",
    "- Remaining positions correspond to Universal POS tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Train word embeddings\n",
    "model = Word2Vec(X, min_count=1, vector_size=100)\n",
    "\n",
    "# Constants\n",
    "MAX_SEQ_LEN = 100\n",
    "EMBEDDING_DIM = 100\n",
    "NUM_TAGS = 13\n",
    "\n",
    "# Create embedded word sequences\n",
    "emb_X = np.zeros((EMBEDDING_DIM, len(X), MAX_SEQ_LEN))\n",
    "for i, sentence in enumerate(X):\n",
    "    for j, word in enumerate(sentence[:MAX_SEQ_LEN]):\n",
    "        emb_X[:,i,j] = model.wv[word]\n",
    "\n",
    "# Define POS tags and their one-hot encodings\n",
    "tag_encodings = {\n",
    "    'PAD':  [1,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "    'NOUN': [0,1,0,0,0,0,0,0,0,0,0,0,0],\n",
    "    '.':    [0,0,1,0,0,0,0,0,0,0,0,0,0],\n",
    "    'NUM':  [0,0,0,1,0,0,0,0,0,0,0,0,0],\n",
    "    'ADJ':  [0,0,0,0,1,0,0,0,0,0,0,0,0],\n",
    "    'VERB': [0,0,0,0,0,1,0,0,0,0,0,0,0],\n",
    "    'DET':  [0,0,0,0,0,0,1,0,0,0,0,0,0],\n",
    "    'ADP':  [0,0,0,0,0,0,0,1,0,0,0,0,0],\n",
    "    'CONJ': [0,0,0,0,0,0,0,0,1,0,0,0,0],\n",
    "    'X':    [0,0,0,0,0,0,0,0,0,1,0,0,0],\n",
    "    'PRT':  [0,0,0,0,0,0,0,0,0,0,1,0,0],\n",
    "    'ADV':  [0,0,0,0,0,0,0,0,0,0,0,1,0],\n",
    "    'PRON': [0,0,0,0,0,0,0,0,0,0,0,0,1]\n",
    "}\n",
    "\n",
    "# Create encoded tag sequences\n",
    "enc_Y = np.zeros((NUM_TAGS, len(Y), MAX_SEQ_LEN))\n",
    "for i, sentence in enumerate(Y):\n",
    "    for j, tag in enumerate(sentence[:MAX_SEQ_LEN]):\n",
    "        enc_Y[:,i,j] = tag_encodings[tag]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes:\n",
      "Word embeddings (emb_X): (100, 72202, 100)\n",
      "Tag encodings (enc_Y): (13, 72202, 100)\n"
     ]
    }
   ],
   "source": [
    "# Verify shapes\n",
    "print(\"Data shapes:\")\n",
    "print(f\"Word embeddings (emb_X): {emb_X.shape}\")\n",
    "print(f\"Tag encodings (enc_Y): {enc_Y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization of input embeddings\n",
    "emb_X = (emb_X - emb_X.mean()) / emb_X.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model: Put It All Together\n",
    "\n",
    "### Model Configuration\n",
    "We configure our RNN with:\n",
    "- 40-dimensional hidden states (n_a)\n",
    "- 100-dimensional input embeddings (n_x)\n",
    "- 13-dimensional output for POS tags (n_y)\n",
    "- Batch size of 1000 sequences\n",
    "- Initial learning rate of 5e-3 with decay\n",
    "\n",
    "### Training Process\n",
    "The training loop implements several crucial components:\n",
    "1. Forward Propagation:\n",
    "   - Process batches of embedded sequences\n",
    "   - Generate POS tag predictions\n",
    "   - Cache intermediate values for backprop\n",
    "\n",
    "2. Backward Propagation:\n",
    "   - Compute gradients through time\n",
    "   - Clip gradients to prevent explosion (-5 to 5)\n",
    "   - Accumulate updates for shared parameters\n",
    "\n",
    "3. Parameter Updates:\n",
    "   - Apply gradient descent with learning rate decay\n",
    "   - Monitor gradient norms for stability\n",
    "   - Track accuracy excluding padding tokens\n",
    "\n",
    "4. Performance Monitoring:\n",
    "   - Track accuracy over epochs\n",
    "   - Monitor gradient magnitudes\n",
    "   - Implement learning rate scheduling\n",
    "\n",
    "This training procedure balances computational efficiency with numerical stability through gradient clipping and learning rate adaptation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 \t Accuracy: 0.1249 \t Learning Rate: 0.00495 \t Grad Norm: 380.95\n",
      "Epoch   1 \t Accuracy: 0.3082 \t Learning Rate: 0.00490 \t Grad Norm: 387.10\n",
      "Epoch   2 \t Accuracy: 0.4763 \t Learning Rate: 0.00485 \t Grad Norm: 381.22\n",
      "Epoch   3 \t Accuracy: 0.4237 \t Learning Rate: 0.00480 \t Grad Norm: 362.53\n",
      "Epoch   4 \t Accuracy: 0.5689 \t Learning Rate: 0.00475 \t Grad Norm: 335.57\n",
      "Epoch   5 \t Accuracy: 0.4951 \t Learning Rate: 0.00471 \t Grad Norm: 324.07\n",
      "Epoch   6 \t Accuracy: 0.6364 \t Learning Rate: 0.00466 \t Grad Norm: 314.77\n",
      "Epoch   7 \t Accuracy: 0.5331 \t Learning Rate: 0.00461 \t Grad Norm: 304.52\n",
      "Epoch   8 \t Accuracy: 0.6091 \t Learning Rate: 0.00457 \t Grad Norm: 302.26\n",
      "Epoch   9 \t Accuracy: 0.6701 \t Learning Rate: 0.00452 \t Grad Norm: 299.37\n",
      "Epoch  10 \t Accuracy: 0.5714 \t Learning Rate: 0.00448 \t Grad Norm: 299.18\n",
      "Epoch  11 \t Accuracy: 0.7004 \t Learning Rate: 0.00443 \t Grad Norm: 295.69\n",
      "Epoch  12 \t Accuracy: 0.6235 \t Learning Rate: 0.00439 \t Grad Norm: 292.63\n",
      "Epoch  13 \t Accuracy: 0.7143 \t Learning Rate: 0.00434 \t Grad Norm: 293.61\n",
      "Epoch  14 \t Accuracy: 0.6507 \t Learning Rate: 0.00430 \t Grad Norm: 296.04\n",
      "Epoch  15 \t Accuracy: 0.7186 \t Learning Rate: 0.00426 \t Grad Norm: 295.57\n",
      "Epoch  16 \t Accuracy: 0.6749 \t Learning Rate: 0.00421 \t Grad Norm: 300.74\n",
      "Epoch  17 \t Accuracy: 0.7230 \t Learning Rate: 0.00417 \t Grad Norm: 299.13\n",
      "Epoch  18 \t Accuracy: 0.7075 \t Learning Rate: 0.00413 \t Grad Norm: 300.15\n",
      "Epoch  19 \t Accuracy: 0.7249 \t Learning Rate: 0.00409 \t Grad Norm: 298.16\n",
      "Epoch  20 \t Accuracy: 0.7058 \t Learning Rate: 0.00405 \t Grad Norm: 302.18\n",
      "Epoch  21 \t Accuracy: 0.7242 \t Learning Rate: 0.00401 \t Grad Norm: 300.64\n",
      "Epoch  22 \t Accuracy: 0.7081 \t Learning Rate: 0.00397 \t Grad Norm: 307.83\n",
      "Epoch  23 \t Accuracy: 0.7184 \t Learning Rate: 0.00393 \t Grad Norm: 300.78\n",
      "Epoch  24 \t Accuracy: 0.7114 \t Learning Rate: 0.00389 \t Grad Norm: 311.37\n",
      "Epoch  25 \t Accuracy: 0.7211 \t Learning Rate: 0.00385 \t Grad Norm: 306.75\n",
      "Epoch  26 \t Accuracy: 0.7159 \t Learning Rate: 0.00381 \t Grad Norm: 310.50\n",
      "Epoch  27 \t Accuracy: 0.7240 \t Learning Rate: 0.00377 \t Grad Norm: 311.80\n",
      "Epoch  28 \t Accuracy: 0.7221 \t Learning Rate: 0.00374 \t Grad Norm: 319.40\n",
      "Epoch  29 \t Accuracy: 0.7211 \t Learning Rate: 0.00370 \t Grad Norm: 315.04\n",
      "Epoch  30 \t Accuracy: 0.7276 \t Learning Rate: 0.00366 \t Grad Norm: 320.63\n",
      "Epoch  31 \t Accuracy: 0.7253 \t Learning Rate: 0.00362 \t Grad Norm: 318.77\n",
      "Epoch  32 \t Accuracy: 0.7340 \t Learning Rate: 0.00359 \t Grad Norm: 321.67\n",
      "Epoch  33 \t Accuracy: 0.7255 \t Learning Rate: 0.00355 \t Grad Norm: 318.26\n",
      "Epoch  34 \t Accuracy: 0.7366 \t Learning Rate: 0.00352 \t Grad Norm: 322.68\n",
      "Epoch  35 \t Accuracy: 0.7276 \t Learning Rate: 0.00348 \t Grad Norm: 321.14\n",
      "Epoch  36 \t Accuracy: 0.7380 \t Learning Rate: 0.00345 \t Grad Norm: 326.24\n",
      "Epoch  37 \t Accuracy: 0.7266 \t Learning Rate: 0.00341 \t Grad Norm: 324.33\n",
      "Epoch  38 \t Accuracy: 0.7405 \t Learning Rate: 0.00338 \t Grad Norm: 329.80\n",
      "Epoch  39 \t Accuracy: 0.7294 \t Learning Rate: 0.00334 \t Grad Norm: 328.22\n",
      "Epoch  40 \t Accuracy: 0.7421 \t Learning Rate: 0.00331 \t Grad Norm: 332.96\n",
      "Epoch  41 \t Accuracy: 0.7282 \t Learning Rate: 0.00328 \t Grad Norm: 330.62\n",
      "Epoch  42 \t Accuracy: 0.7436 \t Learning Rate: 0.00325 \t Grad Norm: 337.66\n",
      "Epoch  43 \t Accuracy: 0.7313 \t Learning Rate: 0.00321 \t Grad Norm: 335.01\n",
      "Epoch  44 \t Accuracy: 0.7444 \t Learning Rate: 0.00318 \t Grad Norm: 341.98\n",
      "Epoch  45 \t Accuracy: 0.7322 \t Learning Rate: 0.00315 \t Grad Norm: 339.06\n",
      "Epoch  46 \t Accuracy: 0.7462 \t Learning Rate: 0.00312 \t Grad Norm: 344.70\n",
      "Epoch  47 \t Accuracy: 0.7326 \t Learning Rate: 0.00309 \t Grad Norm: 342.54\n",
      "Epoch  48 \t Accuracy: 0.7467 \t Learning Rate: 0.00306 \t Grad Norm: 346.99\n",
      "Epoch  49 \t Accuracy: 0.7340 \t Learning Rate: 0.00303 \t Grad Norm: 344.67\n",
      "Epoch  50 \t Accuracy: 0.7478 \t Learning Rate: 0.00299 \t Grad Norm: 351.61\n",
      "Epoch  51 \t Accuracy: 0.7348 \t Learning Rate: 0.00296 \t Grad Norm: 347.70\n",
      "Epoch  52 \t Accuracy: 0.7418 \t Learning Rate: 0.00294 \t Grad Norm: 351.96\n",
      "Epoch  53 \t Accuracy: 0.7366 \t Learning Rate: 0.00291 \t Grad Norm: 348.74\n",
      "Epoch  54 \t Accuracy: 0.7418 \t Learning Rate: 0.00288 \t Grad Norm: 355.19\n",
      "Epoch  55 \t Accuracy: 0.7348 \t Learning Rate: 0.00285 \t Grad Norm: 353.68\n",
      "Epoch  56 \t Accuracy: 0.7450 \t Learning Rate: 0.00282 \t Grad Norm: 354.33\n",
      "Epoch  57 \t Accuracy: 0.7343 \t Learning Rate: 0.00279 \t Grad Norm: 355.87\n",
      "Epoch  58 \t Accuracy: 0.7486 \t Learning Rate: 0.00276 \t Grad Norm: 358.44\n",
      "Epoch  59 \t Accuracy: 0.7418 \t Learning Rate: 0.00274 \t Grad Norm: 355.02\n",
      "Epoch  60 \t Accuracy: 0.7514 \t Learning Rate: 0.00271 \t Grad Norm: 360.61\n",
      "Epoch  61 \t Accuracy: 0.7394 \t Learning Rate: 0.00268 \t Grad Norm: 355.83\n",
      "Epoch  62 \t Accuracy: 0.7521 \t Learning Rate: 0.00265 \t Grad Norm: 364.84\n",
      "Epoch  63 \t Accuracy: 0.7413 \t Learning Rate: 0.00263 \t Grad Norm: 358.20\n",
      "Epoch  64 \t Accuracy: 0.7541 \t Learning Rate: 0.00260 \t Grad Norm: 367.56\n",
      "Epoch  65 \t Accuracy: 0.7446 \t Learning Rate: 0.00258 \t Grad Norm: 362.08\n",
      "Epoch  66 \t Accuracy: 0.7549 \t Learning Rate: 0.00255 \t Grad Norm: 371.48\n",
      "Epoch  67 \t Accuracy: 0.7469 \t Learning Rate: 0.00252 \t Grad Norm: 363.36\n",
      "Epoch  68 \t Accuracy: 0.7553 \t Learning Rate: 0.00250 \t Grad Norm: 373.08\n",
      "Epoch  69 \t Accuracy: 0.7480 \t Learning Rate: 0.00247 \t Grad Norm: 367.94\n",
      "Epoch  70 \t Accuracy: 0.7559 \t Learning Rate: 0.00245 \t Grad Norm: 376.02\n",
      "Epoch  71 \t Accuracy: 0.7464 \t Learning Rate: 0.00242 \t Grad Norm: 369.12\n",
      "Epoch  72 \t Accuracy: 0.7555 \t Learning Rate: 0.00240 \t Grad Norm: 379.82\n",
      "Epoch  73 \t Accuracy: 0.7479 \t Learning Rate: 0.00238 \t Grad Norm: 373.36\n",
      "Epoch  74 \t Accuracy: 0.7560 \t Learning Rate: 0.00235 \t Grad Norm: 383.56\n",
      "Epoch  75 \t Accuracy: 0.7485 \t Learning Rate: 0.00233 \t Grad Norm: 377.38\n",
      "Epoch  76 \t Accuracy: 0.7561 \t Learning Rate: 0.00231 \t Grad Norm: 387.95\n",
      "Epoch  77 \t Accuracy: 0.7487 \t Learning Rate: 0.00228 \t Grad Norm: 378.78\n",
      "Epoch  78 \t Accuracy: 0.7573 \t Learning Rate: 0.00226 \t Grad Norm: 389.60\n",
      "Epoch  79 \t Accuracy: 0.7495 \t Learning Rate: 0.00224 \t Grad Norm: 381.18\n",
      "Epoch  80 \t Accuracy: 0.7581 \t Learning Rate: 0.00222 \t Grad Norm: 391.86\n",
      "Epoch  81 \t Accuracy: 0.7507 \t Learning Rate: 0.00219 \t Grad Norm: 382.62\n",
      "Epoch  82 \t Accuracy: 0.7583 \t Learning Rate: 0.00217 \t Grad Norm: 391.59\n",
      "Epoch  83 \t Accuracy: 0.7509 \t Learning Rate: 0.00215 \t Grad Norm: 385.67\n",
      "Epoch  84 \t Accuracy: 0.7586 \t Learning Rate: 0.00213 \t Grad Norm: 391.53\n",
      "Epoch  85 \t Accuracy: 0.7512 \t Learning Rate: 0.00211 \t Grad Norm: 389.46\n",
      "Epoch  86 \t Accuracy: 0.7590 \t Learning Rate: 0.00209 \t Grad Norm: 393.43\n",
      "Epoch  87 \t Accuracy: 0.7512 \t Learning Rate: 0.00206 \t Grad Norm: 395.01\n",
      "Epoch  88 \t Accuracy: 0.7591 \t Learning Rate: 0.00204 \t Grad Norm: 395.17\n",
      "Epoch  89 \t Accuracy: 0.7514 \t Learning Rate: 0.00202 \t Grad Norm: 397.96\n",
      "Epoch  90 \t Accuracy: 0.7596 \t Learning Rate: 0.00200 \t Grad Norm: 395.28\n",
      "Epoch  91 \t Accuracy: 0.7512 \t Learning Rate: 0.00198 \t Grad Norm: 401.38\n",
      "Epoch  92 \t Accuracy: 0.7603 \t Learning Rate: 0.00196 \t Grad Norm: 397.45\n",
      "Epoch  93 \t Accuracy: 0.7525 \t Learning Rate: 0.00194 \t Grad Norm: 405.14\n",
      "Epoch  94 \t Accuracy: 0.7609 \t Learning Rate: 0.00192 \t Grad Norm: 399.48\n",
      "Epoch  95 \t Accuracy: 0.7540 \t Learning Rate: 0.00191 \t Grad Norm: 407.82\n",
      "Epoch  96 \t Accuracy: 0.7610 \t Learning Rate: 0.00189 \t Grad Norm: 400.32\n",
      "Epoch  97 \t Accuracy: 0.7537 \t Learning Rate: 0.00187 \t Grad Norm: 412.67\n",
      "Epoch  98 \t Accuracy: 0.7610 \t Learning Rate: 0.00185 \t Grad Norm: 402.49\n",
      "Epoch  99 \t Accuracy: 0.7539 \t Learning Rate: 0.00183 \t Grad Norm: 414.78\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(1)\n",
    "\n",
    "# Model dimensions\n",
    "n_a = 40        # hidden state size\n",
    "n_x = 100       # input size (embedding dimension)\n",
    "n_y = 13        # output size (number of POS tags)\n",
    "batch_size = 1000\n",
    "learning_rate = 5e-3\n",
    "\n",
    "# Initialize parameters\n",
    "parameters = {\n",
    "    \"Wax\": np.random.randn(n_a, n_x) * 0.02,   # Input weights\n",
    "    \"Waa\": np.random.randn(n_a, n_a) * 0.02,   # Hidden weights\n",
    "    \"Wya\": np.random.randn(n_y, n_a) * 0.02,   # Output weights\n",
    "    \"ba\": np.random.randn(n_a, batch_size) * 0.02,  # Hidden bias\n",
    "    \"by\": np.random.randn(n_y, batch_size) * 0.02   # Output bias\n",
    "}\n",
    "\n",
    "# Initialize hidden state\n",
    "a0 = np.random.randn(n_a, batch_size) * 0.02\n",
    "\n",
    "# Training loop\n",
    "accuracies = []\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    a, y_pred, caches = rnn_forward(emb_X[:, :batch_size, :], \n",
    "                                  enc_Y[:, :batch_size, :], \n",
    "                                  a0, \n",
    "                                  parameters)\n",
    "    \n",
    "    # Backward pass\n",
    "    gradients = rnn_backward(caches)\n",
    "    \n",
    "    # Clip gradients\n",
    "    for grad_name, grad_value in gradients.items():\n",
    "        np.clip(grad_value, -5, 5, out=gradients[grad_name])\n",
    "    \n",
    "    # Update parameters\n",
    "    for param_name, param_value in parameters.items():\n",
    "        grad_name = f\"d{param_name}_total\"\n",
    "        parameters[param_name] += -learning_rate * gradients[grad_name]\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    predictions = np.argmax(y_pred, axis=0)\n",
    "    output = np.zeros_like(y_pred)\n",
    "    for i in range(batch_size):\n",
    "        for j in range(y_pred.shape[2]):  # sequence length\n",
    "            output[predictions[i,j], i, j] = 1\n",
    "    \n",
    "    # Calculate accuracy excluding padding tag (index 0)\n",
    "    correct_predictions = np.multiply(enc_Y[1:, :batch_size, :], output[1:, :, :]).sum()\n",
    "    total_tags = enc_Y[1:, :batch_size, :].sum()\n",
    "    accuracy = correct_predictions / total_tags\n",
    "    \n",
    "    grad_norm = np.sqrt(sum(np.sum(grad**2) for grad in gradients.values()))\n",
    "\n",
    "    # Try with learning rate scheduling\n",
    "    if learning_rate > 1e-3:\n",
    "        learning_rate *= 0.99  # Decay over time\n",
    "\n",
    "    accuracies.append(accuracy)\n",
    "    print(f\"Epoch {epoch:3d} \\t Accuracy: {accuracy:.4f} \\t Learning Rate: {learning_rate:.5f} \\t Grad Norm: {grad_norm:.2f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Moment of Truth: How Did We Do? 📊\n",
    "\n",
    "Our humble RNN, built with nothing but numpy and determination, managed to achieve:\n",
    "- ~76% accuracy (not exactly ChatGPT territory, but hey, we'll take it!)\n",
    "- Stable training \n",
    "- Actual learning\n",
    "\n",
    "Sure, we won't be challenging state-of-the-art models anytime soon, but for a \"homemade\" RNN:\n",
    "- No fancy attention mechanisms\n",
    "- No transformer architecture\n",
    "- No 175 billion parameters\n",
    "- Just pure, vanilla RNN goodness\n",
    "\n",
    "Let's visualize our journey from random guessing to \"actually not terrible\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training progress\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(accuracies)\n",
    "plt.title('Training Accuracy over Time')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(ls = ':', color = 'gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
